{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7051f57-124d-44c7-80ac-fff46282fd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 20)\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from name_variation import NameVariationGenerator\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import Levenshtein\n",
    "from itertools import combinations, chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97a4735-6d5f-43cc-9ed5-49e21012c632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_json(path: str):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ef499f-d5a8-4a2a-b659-d606cd9dfc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing_name(dataset, *name_cols):\n",
    "    for col in name_cols:\n",
    "        dataset[col] = dataset[col].apply(lambda x: re.sub('[0-9]', '', unidecode(x).lower().strip()))\n",
    "        dataset = dataset[dataset[col].apply(lambda x: len(x)>=2)].reset_index(drop=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c975b-eaba-4f36-a494-a4abb7c56b08",
   "metadata": {},
   "source": [
    "### Names by country (Wikidata - List of most popular first and last names by country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb27e88f-6a32-42da-bdfc-d4dbec2bba05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_f = pd.read_csv('data/common-forenames-by-country.csv')\n",
    "df_f = df_f[['Romanized Name', 'Country']].astype(str).rename(columns={'Romanized Name': 'FirstName', 'Country': 'country'}).drop_duplicates(ignore_index=True)\n",
    "df_s = pd.read_csv('data/common-surnames-by-country.csv')\n",
    "df_s = df_s[['Romanized Name', 'Country']].astype(str).rename(columns={'Romanized Name': 'LastName', 'Country': 'country'}).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb24c1de-d804-4424-86af-0f6573eb8dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "df_f = preprocessing_name(df_f, 'FirstName', 'country')\n",
    "df_s = preprocessing_name(df_s, 'LastName', 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "909f57f9-ae61-4c02-a096-ae335e3afdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# countries with both forenames and surnames\n",
    "df_f_bc = df_f.merge(df_s[['country']].drop_duplicates(), on='country', how='inner')\n",
    "df_s_bc = df_s.merge(df_f[['country']].drop_duplicates(), on='country', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8761f79e-a6c7-49d4-a681-7e2d2800f639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting train and test givennames and sirnames\n",
    "train_f, val_f = train_test_split(df_f_bc, test_size=0.3, random_state=42, shuffle=True, stratify=df_f_bc['country'])\n",
    "train_s, val_s = train_test_split(df_s_bc, test_size=0.3, random_state=42, shuffle=True, stratify=df_s_bc['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1dcf4980-515a-45ba-89a0-784e9b78d605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove accented characters and lowercase full names by joining givennames and sirnames by country\n",
    "train_names_by_country = train_f.merge(train_s, on='country')\n",
    "train_names_by_country['name'] = train_names_by_country['FirstName'] + ' ' + train_names_by_country['LastName']\n",
    "val_names_by_country = val_f.merge(val_s, on='country')\n",
    "val_names_by_country['name'] = val_names_by_country['FirstName'] + ' ' + val_names_by_country['LastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ea7603-16f0-4695-ab7b-07996802e31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_variation_generator = NameVariationGenerator()\n",
    "train_names = pd.DataFrame({})\n",
    "val_names = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85a655b-e90f-4e16-8068-e7136985a5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2621/2621 [00:00<00:00, 152204.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se\n",
      "(2621, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2621/2621 [00:00<00:00, 54646.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab\n",
      "(5242, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2621/2621 [00:00<00:00, 120976.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj\n",
      "(7863, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2621/2621 [00:00<00:00, 54516.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm\n",
      "(10484, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2621/2621 [00:00<00:00, 132871.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse\n",
      "(13105, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:10<00:00, 241.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = kte\n",
      "(15726, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:10<00:00, 242.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se_kte\n",
      "(18347, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:10<00:00, 238.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab_kte\n",
      "(20968, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:11<00:00, 234.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj_kte\n",
      "(23589, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:10<00:00, 241.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm_kte\n",
      "(26210, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2621/2621 [00:10<00:00, 238.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variations in ('se', 'ab', 'wj', 'wm', 'tse', 'kte', \\\n",
    "                   'se_kte', 'ab_kte', 'wj_kte', 'wm_kte', 'tse_kte'):\n",
    "    print(train_names.shape)\n",
    "    train_names = pd.concat([train_names, name_variation_generator.\\\n",
    "                             generate_name_variations(train_names_by_country, variations, 0.1)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d57b953-03a5-4ed7-bbcd-39b1ba260209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 485/485 [00:00<00:00, 96974.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 485/485 [00:00<00:00, 49996.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 485/485 [00:00<00:00, 80570.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 485/485 [00:00<00:00, 26863.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 485/485 [00:00<00:00, 86244.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 235.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 216.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 234.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 226.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 229.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:02<00:00, 232.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variations in ('se', 'ab', 'wj', 'wm', 'tse', 'kte', \\\n",
    "                   'se_kte', 'ab_kte', 'wj_kte', 'wm_kte', 'tse_kte'):\n",
    "    val_names = pd.concat([val_names, name_variation_generator.\\\n",
    "                           generate_name_variations(val_names_by_country, variations, 0.1)\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d1380-a910-4bea-bce7-25fdb79da819",
   "metadata": {},
   "source": [
    "### OCR dataset (Kaggle Handwritten names dataset + pyteserract 4.0 model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b91d3a-014c-4a55-ba61-6a6eafefd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df_ocr = pd.read_csv('data/ocr_names.csv', index_col=0).dropna().drop_duplicates(ignore_index=True)\n",
    "\n",
    "# preprocessing\n",
    "df_ocr = preprocessing_name(df_ocr, 'ocr_name', 'true_name')\n",
    "df_ocr = df_ocr[df_ocr['true_name']!=df_ocr['ocr_name']].reset_index(drop=True)\n",
    "\n",
    "# splitting train and test ocrnames\n",
    "train_names_ocr, val_names_ocr = train_test_split(df_ocr, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a891240a-4fff-4e90-ad61-6aace6780b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names_ocr['variations'] = 'ocr'\n",
    "train_names = pd.concat([train_names, train_names_ocr.rename(\n",
    "                             columns={'true_name': 'name1', 'ocr_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])\n",
    "val_names_ocr['variations'] = 'ocr'\n",
    "val_names = pd.concat([val_names, val_names_ocr.rename(\n",
    "                             columns={'true_name': 'name1', 'ocr_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "104632c2-c382-4ec5-9109-128c9f80caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2395/2395 [00:00<00:00, 117081.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 78413.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ocr_tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 419.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ocr_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_names_ocr['orig_error_length'] = train_names_ocr[['true_name', 'ocr_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "for variations in ('tse', 'kte'):\n",
    "    train_names = pd.concat([train_names, name_variation_generator.\\\n",
    "                           generate_name_variations(train_names_ocr, variations, 0.1, 'ocr_name', \\\n",
    "                                                    'true_name', 'ocr', 'orig_error_length')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5d068e-bacc-4baf-9faf-6265d82adb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 599/599 [00:00<00:00, 92255.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 59854.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ocr_tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 414.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ocr_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_names_ocr['orig_error_length'] = val_names_ocr[['true_name', 'ocr_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "for variations in ('tse', 'kte'):\n",
    "    val_names = pd.concat([val_names, name_variation_generator.\\\n",
    "                           generate_name_variations(train_names_ocr, variations, 0.1, 'ocr_name', \\\n",
    "                                                    'true_name', 'ocr', 'orig_error_length')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d92746-a9d7-45dd-8901-a1bd5240ac5e",
   "metadata": {},
   "source": [
    "### Alternative names dataset - Wikidata (Language/Spellings/Regional/Phonetic variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32197301-e8b4-4b71-ba60-d229b6c1ea2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read dataset\n",
    "alt_names_data = [read_json('data/results.json')]\n",
    "alt_names_data.extend(list(read_json('data/results_lang.json').values()))\n",
    "\n",
    "# preprocessing\n",
    "def preprocessing_alt_names(alt_names_data):\n",
    "    alt_names_pairs_data = []\n",
    "    for alt_names_json in alt_names_data:\n",
    "        alt_names_pairs = [(name_dict['nameLabelString']['value'], name_dict['nameAltLabelString']['value']) \\\n",
    "                       for name_dict in alt_names_json['results']['bindings']]\n",
    "        alt_names_pairs_data.extend(alt_names_pairs)    \n",
    "    df_alt = pd.DataFrame(alt_names_pairs_data, columns=['true_name', 'alt_name'])    \n",
    "    df_alt = preprocessing_name(df_alt, 'alt_name', 'true_name')\n",
    "    df_alt = df_alt[df_alt['true_name']!=df_alt['alt_name']].reset_index(drop=True)\n",
    "    return df_alt\n",
    "df_alt = preprocessing_alt_names(alt_names_data)\n",
    "\n",
    "# splitting train and test transliterated names\n",
    "train_names_alt, val_names_alt = train_test_split(df_alt, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c678275b-b9ea-49d2-8f48-9c00410bd137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names_alt['variations'] = 'alt'\n",
    "train_names = pd.concat([train_names, train_names_alt.rename(\n",
    "                             columns={'true_name': 'name1', 'alt_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])\n",
    "val_names_alt['variations'] = 'alt'\n",
    "val_names = pd.concat([val_names, val_names_alt.rename(\n",
    "                             columns={'true_name': 'name1', 'alt_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf82bf68-3d82-4933-a164-1e07c5caa5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10375/10375 [00:00<00:00, 145802.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1037/1037 [00:00<00:00, 118208.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = alt_tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1037/1037 [00:02<00:00, 490.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = alt_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_names_alt['orig_error_length'] = train_names_alt[['true_name', 'alt_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "for variations in ('tse', 'kte'):\n",
    "    train_names = pd.concat([train_names, name_variation_generator.\\\n",
    "                           generate_name_variations(train_names_alt, variations, 0.1, 'alt_name', \\\n",
    "                                                    'true_name', 'alt', 'orig_error_length')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6dd9cd7-c4df-4357-a99c-973f0879ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2594/2594 [00:00<00:00, 158077.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 259/259 [00:00<00:00, 129679.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = alt_tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 259/259 [00:00<00:00, 498.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = alt_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_names_alt['orig_error_length'] = val_names_alt[['true_name', 'alt_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "for variations in ('tse', 'kte'):\n",
    "    val_names = pd.concat([val_names, name_variation_generator.\\\n",
    "                           generate_name_variations(val_names_alt, variations, 0.1, 'alt_name', \\\n",
    "                                                    'true_name', 'alt', 'orig_error_length')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99d7d2-f58f-4a2c-9f99-495401a937ca",
   "metadata": {},
   "source": [
    "### Nick/Pen names dataset (https://github.com/carltonnorthern/nicknames/blob/master/names.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f182ee0b-d61b-4412-a15c-d72efa1f9e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read dataset\n",
    "with open('data/nicknames.txt', 'r') as f:\n",
    "    names = f.readlines()\n",
    "\n",
    "def preprocess_nicknames(names):\n",
    "    names_list = [nicknames.strip().split(',') for nicknames in names]\n",
    "    pair_names = chain.from_iterable([list(combinations(nicknames,2)) for nicknames in names_list])\n",
    "    df_pen_1 = pd.DataFrame(pair_names, columns=['true_name', 'pen_name'])\n",
    "    df_pen_2 = pd.DataFrame(pair_names, columns=['pen_name', 'true_name'])\n",
    "    df_pen = pd.concat([df_pen_1, df_pen_2], ignore_index=True)\n",
    "    df_pen = preprocessing_name(df_pen, 'pen_name', 'true_name')\n",
    "    return df_pen\n",
    "\n",
    "#preprocessing\n",
    "df_pen = preprocess_nicknames(names)\n",
    "df_pen = df_pen[df_pen['true_name']!=df_pen['pen_name']].reset_index(drop=True)\n",
    "\n",
    "# splitting train and test transliterated names\n",
    "train_names_pen, val_names_pen = train_test_split(df_pen, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab6fb7e-a49a-4e91-837b-fc6e2787a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names_pen['variations'] = 'pen'\n",
    "train_names = pd.concat([train_names, train_names_pen.rename(\n",
    "                             columns={'true_name': 'name1', 'pen_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])\n",
    "val_names_pen['variations'] = 'pen'\n",
    "val_names = pd.concat([val_names, val_names_pen.rename(\n",
    "                             columns={'true_name': 'name1', 'pen_name': 'name2'}\n",
    "                         )[['name1', 'name2', 'variations']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ed7954-e297-4630-a495-a61637f9ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4519/4519 [00:00<00:00, 141761.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 451/451 [00:00<00:00, 522.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = pen_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_names_pen['orig_error_length'] = train_names_pen[['true_name', 'pen_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "train_names = pd.concat([train_names, name_variation_generator.\\\n",
    "                       generate_name_variations(train_names_pen, 'kte', 0.1, 'pen_name', 'true_name', 'pen', 'orig_error_length')\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "011a72bf-3587-4971-be69-c33a7044b100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1937/1937 [00:00<00:00, 143426.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 193/193 [00:00<00:00, 620.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = pen_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_names_pen['orig_error_length'] = val_names_pen[['true_name', 'pen_name']].progress_apply(lambda vec: Levenshtein.distance(vec[0], vec[1]), axis=1)\n",
    "val_names = pd.concat([val_names, name_variation_generator.\\\n",
    "                       generate_name_variations(val_names_pen, 'kte', 0.1, 'pen_name', 'true_name', 'pen', 'orig_error_length')\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840e562-d378-4477-b3ab-30924d69dfe1",
   "metadata": {},
   "source": [
    "### Compound names dataset (Wikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff422e36-aa4c-493a-b19b-fa6192ecaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "compound_names_json = read_json('data/results_compound_names.json')\n",
    "\n",
    "# preprocessing\n",
    "def preprocessing_compound_names(compound_names_json):\n",
    "    compound_names_data = [(names_dict['nameLabel']['value'],) for names_dict in compound_names_json['results']['bindings']]\n",
    "    df_cn = pd.DataFrame(compound_names_data, columns=['compound_name'])\n",
    "    df_cn = preprocessing_name(df_cn, 'compound_name')\n",
    "    df_cn = df_cn.dropna().drop_duplicates(ignore_index=True)\n",
    "    return df_cn\n",
    "df_cn = preprocessing_compound_names(compound_names_json)\n",
    "\n",
    "# splitting train and test transliterated names\n",
    "train_names_cn, val_names_cn = train_test_split(df_cn, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "413c6333-ccce-4247-bfff-00a466d7d496",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 112808.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = he\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 97203.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 33848.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 84459.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 144391.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 161878.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 212.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 202.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 198.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 200.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 226.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 230.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 769/769 [00:03<00:00, 228.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = he_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variations in ('he', 'se', 'ab', 'wj', 'wm', 'tse', 'kte'\\\n",
    "                   , 'se_kte', 'ab_kte', 'wj_kte', 'wm_kte', 'tse_kte', 'he_kte'):\n",
    "    train_names = pd.concat([train_names, name_variation_generator.\\\n",
    "                           generate_name_variations(train_names_cn, variations, 0.1, 'compound_name')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ed69ef-e3fe-4811-b431-1857ff356667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 101782.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = he\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 192197.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 27079.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 95744.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 18751.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 63979.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 227.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 219.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = se_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 216.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = ab_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 216.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wj_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 199.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = wm_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 207.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = tse_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 214.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, Variations = he_kte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variations in ('he', 'se', 'ab', 'wj', 'wm', 'tse', 'kte', \\\n",
    "                   'se_kte', 'ab_kte', 'wj_kte', 'wm_kte', 'tse_kte', 'he_kte'):\n",
    "    val_names = pd.concat([val_names, name_variation_generator.\\\n",
    "                           generate_name_variations(val_names_cn, variations, 0.1, 'compound_name')\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "989dd2fe-f22a-45c2-9f9c-f477b1c3cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names.to_csv('data/train_names_matches.csv', index=False)\n",
    "val_names.to_csv('data/val_names_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98297e-34c7-4df4-9be0-95e12080e4b5",
   "metadata": {},
   "source": [
    "#errors\n",
    "se\n",
    "ab\n",
    "wj\n",
    "wm\n",
    "kte\n",
    "tse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54b1dd-c36f-40f0-99c5-92745f77bc71",
   "metadata": {},
   "source": [
    "#datasets\n",
    "train_names_by_country\n",
    "val_names_by_country\n",
    "ocr->single names - train, val\n",
    "transliteration(phonetic variations)->single names - train, val\n",
    "nicknames - train, val\n",
    "compound_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9968e-82a7-4f0c-9d92-b02437dcaaf7",
   "metadata": {},
   "source": [
    "#level 1 - can be handled by control mechanism (on by_country and cn)\n",
    "se\n",
    "ab\n",
    "wj\n",
    "wm\n",
    "tse\n",
    "nicknames_dataset\n",
    "he(only_cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d09c-8195-4a0d-81a4-f35bf9f1cb48",
   "metadata": {
    "tags": []
   },
   "source": [
    "#level 2 - single error source, error length controllable based on distribution (on by_country and cn)\n",
    "kte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36285938-1461-43ca-a53f-fa3de01a06d8",
   "metadata": {},
   "source": [
    "#level 3 - single error source, error length non-controllable, predefined in dataset \n",
    "ocr->sn\n",
    "transliteration_dataset(phonetic variations)->sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6cc58-d227-4ae4-84eb-1e07c4e0f8e4",
   "metadata": {},
   "source": [
    "#level 4 - 2 levels of variations, error length controllable based on distribution (on by_country and cn)\n",
    "se kte\n",
    "ab kte\n",
    "wj kte\n",
    "wm kte\n",
    "tse kte\n",
    "he(only_cn) kte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941a091-b2b0-4df9-a28c-79d211f0449f",
   "metadata": {},
   "source": [
    "#level 5 - 2 levels of variations, error length non controllable\n",
    "ocr->sn tse\n",
    "ocr->sn kte\n",
    "nicknames_dataset kte\n",
    "transliteration_dataset(phonetic variations)->sn kte\n",
    "transliteration_dataset(phonetic variations)->sn tse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782a7ea-db82-4d45-982e-a7196e8c1d5b",
   "metadata": {},
   "source": [
    "### Generate name mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25726ce3-70af-4597-be9d-8a486a933576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_names_by_country = train_names_by_country[['name', 'country', 'FirstName', 'LastName']].rename(columns={'name': 'name1'})\n",
    "val_names_by_country = val_names_by_country[['name', 'country', 'FirstName', 'LastName']].rename(columns={'name': 'name1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b03a4a0c-85f7-4903-878d-2c6e1201457e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# level 1 - random permutation\n",
    "train_names_random = train_names_by_country.copy()\n",
    "train_names_random['name2'] = train_names_random['name1'].sample(frac=1, random_state=42).values\n",
    "train_names_random['mismatch'] = 'random'\n",
    "val_names_random = val_names_by_country.copy()\n",
    "val_names_random['name2'] = val_names_random['name1'].sample(frac=1, random_state=42).values\n",
    "val_names_random['mismatch'] = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26566fee-33b6-4e7e-9556-f1cb0948f213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# level 2 - random permutation within country\n",
    "train_names_random_in_country = train_names_by_country.copy()\n",
    "train_names_random_in_country['name2'] = train_names_random_in_country.groupby('country')['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "train_names_random_in_country['mismatch'] = 'random_same_country'\n",
    "val_names_random_in_country = val_names_by_country.copy()\n",
    "val_names_random_in_country['name2'] = val_names_random_in_country.groupby('country')['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "val_names_random_in_country['mismatch'] = 'random_same_country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8eb8fec9-8c33-42bb-a22f-ebb1027b5173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# level 3 (I) - random permutation within country and same Firstname\n",
    "train_names_random_in_country_same_firstname = train_names_by_country.copy()\n",
    "train_names_random_in_country_same_firstname['name2'] = train_names_random_in_country_same_firstname.groupby(['country', 'FirstName'])['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "train_names_random_in_country_same_firstname['mismatch'] = 'random_same_country_same_firstname'\n",
    "val_names_random_in_country_same_firstname = val_names_by_country.copy()\n",
    "val_names_random_in_country_same_firstname['name2'] = val_names_random_in_country_same_firstname.groupby(['country', 'FirstName'])['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "val_names_random_in_country_same_firstname['mismatch'] = 'random_same_country_same_firstname'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6d695297-282e-462c-93c2-a39b7e4a4809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# level 3 (II) - random permutation within country and same Lastname\n",
    "train_names_random_in_country_same_lastname = train_names_by_country.copy()\n",
    "train_names_random_in_country_same_lastname['name2'] = train_names_random_in_country_same_lastname.groupby(['country', 'LastName'])['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "train_names_random_in_country_same_lastname['mismatch'] = 'random_same_country_same_lastname'\n",
    "val_names_random_in_country_same_lastname = val_names_by_country.copy()\n",
    "val_names_random_in_country_same_lastname['name2'] = val_names_random_in_country_same_lastname.groupby(['country', 'LastName'])['name1'].transform(lambda x: x.sample(frac=1, random_state=42).values)\n",
    "val_names_random_in_country_same_lastname['mismatch'] = 'random_same_country_same_lastname'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f7a994d-da04-406f-bbb5-4b6048c0b7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_names_mismatch = pd.concat([train_names_random, train_names_random_in_country, train_names_random_in_country_same_firstname, train_names_random_in_country_same_lastname]).reset_index(drop=True)[['name1', 'name2', 'mismatch']]\n",
    "val_names_mismatch = pd.concat([val_names_random, val_names_random_in_country, val_names_random_in_country_same_firstname, val_names_random_in_country_same_lastname]).reset_index(drop=True)[['name1', 'name2', 'mismatch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a65a976-dc7a-4a16-abe6-d8c14facdd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_names_mismatch.to_csv('train_names_mismatches.csv')\n",
    "val_names_mismatch.to_csv('val_names_mismatches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0dfa40-2fc1-4387-aa1d-f0feb12535e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9661e5-10a1-488e-9a24-3025f880c92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mw)",
   "language": "python",
   "name": "mw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
